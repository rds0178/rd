{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOSoaLvnD2ZLuXQJMLul45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rds0178/rd/blob/main/CV_Exm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz2hzMYe9FiU"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "img=cv2.imread(\"image.jpg\",0)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "img=cv2.imread(\"image.jpg\")\n",
        "ig = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(ig)"
      ],
      "metadata": {
        "id": "xy2FVHRf-Qfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2a. Image Resizing\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "image = cv2.imread('image.jpg')\n",
        "bigger = cv2.resize(image, (300, 400))\n",
        "cv2_imshow(bigger)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "fR7VeGBG-eZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2b. Flip\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread(\"bat.jpg\")\n",
        "flipped_img = cv2.flip(img,1)\n",
        "cv2_imshow(flipped_img)"
      ],
      "metadata": {
        "id": "5l5cLoQUjnBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3a. Contours\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"fruits.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
        "_, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
        "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "contour_img = cv2.drawContours(img.copy(), contours, -1, (0, 0, 255), 2)\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(contour_img)"
      ],
      "metadata": {
        "id": "x74BGg3fk7Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3b. Blending\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img1 = cv2.imread('/content/sample_data/images.jpg')\n",
        "img2 = cv2.imread('/content/sample_data/Untitled.jpg')\n",
        "resize1 = cv2.resize(img1,(1000,1000))\n",
        "resize2 = cv2.resize(img2,(1000,1000))\n",
        "\n",
        "blend = cv2.addWeighted(resize1, 0.5, resize2, 0.5, 0)\n",
        "cv2_imshow(blend)"
      ],
      "metadata": {
        "id": "ZhDJWgKllfH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Make Borders\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "image = cv2.imread('image.jpg')\n",
        "image = cv2.copyMakeBorder(image, 10, 10, 10, 10, cv2.BORDER_CONSTANT)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "4HpcPk8SAVf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Histogram Equalisation\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('image.jpg')\n",
        "\n",
        "yuv_img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "\n",
        "yuv_img[:,:,0] = cv2.equalizeHist(yuv_img[:,:,0])\n",
        "\n",
        "equi_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)\n",
        "cv2_imshow(equi_img)\n",
        "y,u,v = cv2.split(yuv_img)\n",
        "cv2_imshow(y)\n",
        "cv2_imshow(u)\n",
        "cv2_imshow(v)"
      ],
      "metadata": {
        "id": "mgwvEhdiSWRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Image Blurring\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('3.png')\n",
        "avging = cv2.blur(img,(10,10))\n",
        "cv2_imshow(avging)\n",
        "  #Gaussian Blurring\n",
        "gausBlur = cv2.GaussianBlur(img, (5,5),0)\n",
        "cv2_imshow(gausBlur)\n",
        "  # Median blurring\n",
        "medBlur = cv2.medianBlur(img,5)\n",
        "cv2_imshow(medBlur)"
      ],
      "metadata": {
        "id": "l1Vm-ZSBAsqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Image Sharpening\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('2.jpg')\n",
        "sharpeningKernel = np.array(([0, -1, 0], [-1, 5, -1], [0, -1, 0]), dtype=\"int\")\n",
        "output = cv2.filter2D(img, -1, sharpeningKernel)\n",
        "cv2_imshow(output)"
      ],
      "metadata": {
        "id": "g8ZHhW86B1gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Color Quantization\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv.imread(\"image.jpg\")\n",
        "pixels = img.reshape((-1, 3)).astype(np.float32)\n",
        "\n",
        "_, labels, centers = cv.kmeans(pixels, 8, None, (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0), 10, cv.KMEANS_RANDOM_CENTERS)\n",
        "quantized_img = np.uint8(centers)[labels.flatten()].reshape(img.shape)\n",
        "\n",
        "cv2_imshow(quantized_img)\n"
      ],
      "metadata": {
        "id": "Er53Fec8muAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Rotate and Translation of Images\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "image = cv2.imread('2.jpg')\n",
        "height, width = image.shape[:2]\n",
        "\n",
        "tx, ty = 50, 50  # Translation in x and y directions\n",
        "center = (width / 2, height / 2)\n",
        "rotation_matrix = cv2.getRotationMatrix2D(center=center, angle=45, scale=1)\n",
        "\n",
        "# Apply rotation using warpAffine\n",
        "rotated_image = cv2.warpAffine(src=image, M=rotation_matrix, dsize=(width, height))\n",
        "\n",
        "# Define the translation matrix\n",
        "translation_matrix = np.float32([[1, 0, tx],\n",
        "                                [0, 1, ty]])\n",
        "\n",
        "translated_image = cv2.warpAffine(src=rotated_image, M=translation_matrix, dsize=(width, height))\n",
        "\n",
        "cv2_imshow(image)\n",
        "cv2_imshow(rotated_image)\n",
        "cv2_imshow(translated_image)"
      ],
      "metadata": {
        "id": "JRJzHUEsGuDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. canny  Edge Detection\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('2.jpg',0)\n",
        "edges = cv.Canny(img,100,200)\n",
        "\n",
        "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
        "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
        "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jetF8e-4LtdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Erosion and Dilation of images\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('2.jpg', 0)\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
        "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(img_erosion)\n",
        "cv2_imshow(img_dilation)"
      ],
      "metadata": {
        "id": "Ol0WwA50MC1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Thresholding segmentation technique\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image = cv2.imread('2.jpg')\n",
        "img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "ret, th1 = cv2.threshold(img, 160, 255, cv2.THRESH_BINARY)\n",
        "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "cv2_imshow(image)\n",
        "cv2_imshow(th1)\n",
        "cv2_imshow(th2)\n",
        "cv2_imshow(th3)"
      ],
      "metadata": {
        "id": "vbZph5biMigP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Filter\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"2.jpg\")\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "lower_green = np.array([50, 100, 50])\n",
        "upper_green = np.array([70, 255, 255])\n",
        "\n",
        "mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "res = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "cv2_imshow(mask)\n",
        "cv2_imshow(hsv)\n",
        "cv2_imshow(res)"
      ],
      "metadata": {
        "id": "oBV8zK_jEI2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vnQ14Hqp95P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}